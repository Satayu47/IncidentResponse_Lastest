# Complete Graph Summary - All IEEE Line Graphs

## ‚úÖ All Graphs Created (Line Graph Format)

### 1. **Your System - Single Incident Accuracy**
**File**: `reports/visualizations/single_incident_accuracy_ieee.png`
- **Type**: Line graph
- **Shows**: Accuracy by OWASP category
- **Result**: 98.0% overall accuracy

### 2. **Your System - Multi-Incident Accuracy**
**File**: `reports/visualizations/multi_incident_accuracy_ieee.png`
- **Type**: Line graph
- **Shows**: Accuracy across 4 metrics
- **Result**: 100% across all metrics

### 3. **Your System - Overall Latency**
**File**: `reports/visualizations/overall_latency_graph_ieee.png`
- **Type**: Line graph
- **Shows**: End-to-end latency (10 test cases)
- **Result**: 123.48 ms average

### 4. **Accuracy Comparison (Your System vs OpenAI)**
**File**: `reports/visualizations/accuracy_comparison_ieee.png`
- **Type**: Line graph
- **Shows**: Your system (98.0%) vs OpenAI (95.0%)
- **Result**: +3.0% advantage for your system

### 5. **Latency Comparison (Your System vs OpenAI)**
**File**: `reports/visualizations/latency_comparison_ieee.png`
- **Type**: Line graph
- **Shows**: Your system (123.5 ms) vs OpenAI (94.4 ms)
- **Result**: OpenAI faster, but your system more accurate

### 6. **Combined Comparison (Latency & Accuracy)**
**File**: `reports/visualizations/combined_latency_accuracy_comparison_ieee.png`
- **Type**: Side-by-side line graphs
- **Shows**: Both latency and accuracy in one view
- **Left**: Latency comparison (10 test cases)
- **Right**: Accuracy comparison

### 7. **Dual-Axis Combined View**
**File**: `reports/visualizations/dual_axis_comparison_ieee.png`
- **Type**: Dual Y-axis line graph
- **Shows**: Latency (left axis) and Accuracy (right axis) together
- **Unique**: Shows both metrics on same test cases

## üìä Quick Reference

| Graph | Your System | OpenAI Baseline | Advantage |
|-------|-------------|-----------------|-----------|
| **Accuracy** | 98.0% | 95.0% | **+3.0%** ‚úÖ |
| **Latency** | 123.5 ms | 94.4 ms | -29.1 ms (but more accurate) |

## üìÅ All Graph Files

All graphs are in: `reports/visualizations/`

1. `single_incident_accuracy_ieee.png`
2. `multi_incident_accuracy_ieee.png`
3. `overall_latency_graph_ieee.png`
4. `accuracy_comparison_ieee.png`
5. `latency_comparison_ieee.png`
6. `combined_latency_accuracy_comparison_ieee.png` ‚≠ê **NEW**
7. `dual_axis_comparison_ieee.png` ‚≠ê **NEW**

## üìù For Your D3 Report

### Recommended Graphs to Include:

1. **Fig. X - Overall System Latency**: Shows your system performance
2. **Fig. Y - Accuracy Comparison**: Shows your system outperforms baseline
3. **Fig. Z - Combined Comparison**: Shows both metrics together (recommended!)

### Key Talking Points:

- **Accuracy**: Your system achieves 98.0% vs 95.0% for OpenAI (+3.0%)
- **Latency**: Your system averages 123.5 ms vs 94.4 ms for OpenAI
- **Trade-off**: Slightly slower but significantly more accurate
- **Real-world**: 123 ms is still very fast for incident response (acceptable)

---

**Status**: ‚úÖ Complete set of 7 IEEE-format line graphs ready!

